{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cd5ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f8663ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base for the autoencoder\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size = 4, output_size = 1):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbdc75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "\n",
    "myDF = pd.read_excel(\"Copy of Folds5x2_pp.xlsx\")\n",
    "cleanDF = myDF.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3cfd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input columns: ['AT', 'V', 'AP', 'RH']\n",
      "Output column: PE\n"
     ]
    }
   ],
   "source": [
    "#assigning columns\n",
    "\n",
    "output_column = cleanDF.columns[-1]\n",
    "input_columns = [col for col in cleanDF.columns if col != output_column]\n",
    "\n",
    "print(\"Input columns:\", input_columns)\n",
    "print(\"Output column:\", output_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0add555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (9568, 4), Output shape: (9568,)\n",
      "\n",
      "First 5 rows of real data:\n",
      "      AT      V       AP     RH      PE\n",
      "0  14.96  41.76  1024.07  73.17  463.26\n",
      "1  25.18  62.96  1020.04  59.08  444.37\n",
      "2   5.11  39.40  1012.16  92.14  488.56\n",
      "3  20.86  57.32  1010.24  76.64  446.48\n",
      "4  10.82  37.50  1009.23  96.62  473.90\n"
     ]
    }
   ],
   "source": [
    "#extracting data from columns\n",
    "\n",
    "input_data = cleanDF[input_columns].values\n",
    "output_data = cleanDF[output_column].values\n",
    "\n",
    "print(f\"Input shape: {input_data.shape}, Output shape: {output_data.shape}\")\n",
    "print(f\"\\nFirst 5 rows of real data:\")\n",
    "print(cleanDF[input_columns + [output_column]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4f09a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data range:\n",
      "AT: 1.81 to 37.11\n",
      "V: 25.36 to 81.56\n",
      "AP: 992.89 to 1033.30\n",
      "RH: 25.56 to 100.16\n",
      "PE: 420.26 to 495.76\n",
      "\n",
      "Normalized data range:\n",
      "AT: -2.39 to 2.34\n",
      "V: -2.28 to 2.14\n",
      "AP: -3.43 to 3.37\n",
      "RH: -3.27 to 1.84\n",
      "PE: -2.00 to 2.43\n",
      "\n",
      "Normalized input shape: (9568, 4), Normalized output shape: (9568,)\n"
     ]
    }
   ],
   "source": [
    "#normalizing data\n",
    "\n",
    "scalar_input = StandardScaler().fit_transform(input_data)\n",
    "scalar_output = StandardScaler().fit_transform(output_data.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Original data range:\")\n",
    "for i, col in enumerate(input_columns):\n",
    "    print(f\"{col}: {input_data[:, i].min():.2f} to {input_data[:, i].max():.2f}\")\n",
    "print(f\"{output_column}: {output_data.min():.2f} to {output_data.max():.2f}\")\n",
    "\n",
    "print(f\"\\nNormalized data range:\")\n",
    "for i, col in enumerate(input_columns):\n",
    "    print(f\"{col}: {scalar_input[:, i].min():.2f} to {scalar_input[:, i].max():.2f}\")\n",
    "print(f\"{output_column}: {scalar_output.min():.2f} to {scalar_output.max():.2f}\")\n",
    "\n",
    "print(f\"\\nNormalized input shape: {scalar_input.shape}, Normalized output shape: {scalar_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5d15447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and testing sets\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(\n",
    "    scalar_input, scalar_output, test_size=0.2, random_state=42\n",
    ")\n",
    "# test_size = 0.2 => 20% data for testing, rest for training\n",
    "\n",
    "input_train_tensor = torch.FloatTensor(input_train)\n",
    "input_test_tensor = torch.FloatTensor(input_test)\n",
    "output_train_tensor = torch.FloatTensor(output_train).unsqueeze(1)\n",
    "output_test_tensor = torch.FloatTensor(output_test).unsqueeze(1)\n",
    "\n",
    "model = Autoencoder(input_size=4, output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "626b90ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/500], Loss: 0.9902\n",
      "Epoch [100/500], Loss: 0.6261\n",
      "Epoch [150/500], Loss: 0.1758\n",
      "Epoch [200/500], Loss: 0.1005\n",
      "Epoch [250/500], Loss: 0.0720\n",
      "Epoch [300/500], Loss: 0.0648\n",
      "Epoch [350/500], Loss: 0.0628\n",
      "Epoch [400/500], Loss: 0.0616\n",
      "Epoch [450/500], Loss: 0.0607\n",
      "Epoch [500/500], Loss: 0.0600\n",
      "\n",
      "Training completed!\n",
      "Final training loss: 0.0600\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "no_of_epochs = 500\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(input_train_tensor)\n",
    "    \n",
    "    loss = criterion(predictions, output_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    if ((epoch + 1) % (no_of_epochs / 10)) == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{no_of_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1475cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss on Real Data: 0.0583\n",
      "\n",
      "Test Metrics on Real Data:\n",
      "Mean Squared Error (MSE): 0.0583\n",
      "Mean Absolute Error (MAE): 0.1897\n",
      "Root Mean Squared Error (RMSE): 0.2414\n",
      "\n",
      "Sample Predictions vs Actual on Real Data:\n",
      "Sample 1: Predicted=0.039, Actual=0.053\n",
      "Sample 2: Predicted=-0.956, Actual=-1.058\n",
      "Sample 3: Predicted=-1.186, Actual=-0.802\n",
      "Sample 4: Predicted=-0.972, Actual=-1.170\n",
      "Sample 5: Predicted=1.502, Actual=1.623\n",
      "Sample 6: Predicted=-0.904, Actual=-1.072\n",
      "Sample 7: Predicted=-0.337, Actual=-0.110\n",
      "Sample 8: Predicted=-1.171, Actual=-1.122\n",
      "Sample 9: Predicted=-1.215, Actual=-1.256\n",
      "Sample 10: Predicted=1.130, Actual=0.709\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(input_test_tensor)\n",
    "    test_loss = criterion(test_predictions, output_test_tensor)\n",
    "\n",
    "print(f\"Test Loss on Real Data: {test_loss.item():.4f}\")\n",
    "\n",
    "test_predictions_numpy = test_predictions.numpy().flatten()\n",
    "output_test_numpy = output_test_tensor.numpy().flatten()\n",
    "\n",
    "mse = np.mean((test_predictions_numpy - output_test_numpy) ** 2)\n",
    "mae = np.mean(np.abs(test_predictions_numpy - output_test_numpy))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nTest Metrics on Real Data:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nSample Predictions vs Actual on Real Data:\")\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i+1}: Predicted={test_predictions_numpy[i]:.3f}, Actual={output_test_numpy[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
