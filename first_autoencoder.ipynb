{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7ab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e7ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "no_of_samples = 1000\n",
    "\n",
    "# generating random variables with mean 0 and std dev 1, 1.5, and 2\n",
    "a = np.random.normal(0,1, no_of_samples)\n",
    "b = np.random.normal(0,1.25, no_of_samples)\n",
    "c = np.random.normal(0,1.5, no_of_samples)\n",
    "d = np.random.normal(0,1.75, no_of_samples)\n",
    "\n",
    "# output is linear combination of x, y, z + some noise (randomness)\n",
    "output = (0.4 * a) + (0.2 * b) + (0.1 * c) + (0.3 * d) + np.random.normal(0, 0.1, no_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65f7e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "\n",
      "a range: -3.24 to 3.85\n",
      "b range: -3.68 to 3.99\n",
      "c range: -4.53 to 5.89\n",
      "d range: -5.13 to 5.68\n",
      "output range: -1.95 to 2.20\n"
     ]
    }
   ],
   "source": [
    "# printing the random data\n",
    "\n",
    "print(\"Data:\\n\")\n",
    "print(f\"a range: {a.min():.2f} to {a.max():.2f}\")\n",
    "print(f\"b range: {b.min():.2f} to {b.max():.2f}\")\n",
    "print(f\"c range: {c.min():.2f} to {c.max():.2f}\")\n",
    "print(f\"d range: {d.min():.2f} to {d.max():.2f}\")\n",
    "print(f\"output range: {output.min():.2f} to {output.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fa27df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame:\n",
      "\n",
      "(1000, 5)\n",
      "          a         b         c         d    output\n",
      "0  0.496714  1.749194 -1.012767 -3.338663 -0.640701\n",
      "1 -0.138264  1.155792 -0.216778 -1.505674 -0.300648\n",
      "2  0.647689  0.074538 -1.188630 -0.723810 -0.060221\n",
      "3  1.523030 -0.808671 -0.461942  3.303453  1.439583\n",
      "4 -0.234153  0.872779 -2.840422  0.973968 -0.047643\n"
     ]
    }
   ],
   "source": [
    "myDF = pd.DataFrame({\n",
    "    'a' : a,\n",
    "    'b' : b,\n",
    "    'c' : c,\n",
    "    'd' : d,\n",
    "    'output' : output\n",
    "})\n",
    "\n",
    "print(\"\\nDataFrame:\\n\")\n",
    "print(myDF.shape)\n",
    "print(myDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c6d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = np.random.choice(no_of_samples, size = int(0.1 * no_of_samples), replace = False)\n",
    "myDF.loc[missing_data, 'a'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa2d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = np.random.choice(no_of_samples, size = int(0.05 * no_of_samples), replace = False)\n",
    "myDF.loc[missing_data, 'c'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e009f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "\n",
      "a         100\n",
      "b           0\n",
      "c          50\n",
      "d           0\n",
      "output      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values:\\n\")\n",
    "print(myDF.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f94a587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (1000, 5)\n",
      "myDF_clean_dropped shape: (856, 5)\n",
      "myDF_clean_filled shape: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original DataFrame shape: {myDF.shape}\")\n",
    "\n",
    "myDF_clean_dropped = myDF.dropna()\n",
    "print(f\"myDF_clean_dropped shape: {myDF_clean_dropped.shape}\")\n",
    "\n",
    "myDF_clean_filled = myDF.fillna(0)\n",
    "print(f\"myDF_clean_filled shape: {myDF_clean_filled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b32271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size = 4, output_size = 1):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afbf6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(input_size = 4, output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3573a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data shape: (1000, 4)\n",
      "output_data shape: (1000, 1)\n",
      "\n",
      "Normalized data:\n",
      "input range: -3.21 to 4.14\n",
      "output range: -2.73 to 3.05\n",
      "\n",
      "Train set: 800 samples\n",
      "Test set: 200 samples\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "input_data = myDF_clean_filled[['a', 'b', 'c', 'd']].values\n",
    "output_data = myDF_clean_filled['output'].values\n",
    "\n",
    "print(f\"input_data shape: {input_data.shape}\")\n",
    "print(f\"output_data shape: {output_data.reshape(-1,1).shape}\")\n",
    "\n",
    "# normalizing data\n",
    "scaled_input_data = StandardScaler().fit_transform(input_data)\n",
    "scaled_output_data = StandardScaler().fit_transform(output_data.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"\\nNormalized data:\")\n",
    "print(f\"input range: {scaled_input_data.min():.2f} to {scaled_input_data.max():.2f}\")\n",
    "print(f\"output range: {scaled_output_data.min():.2f} to {scaled_output_data.max():.2f}\")\n",
    "\n",
    "# splitting data into training and testing sets\n",
    "input_train, input_test, output_train, output_test = train_test_split(\n",
    "    scaled_input_data, scaled_output_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {input_train.shape[0]} samples\")\n",
    "print(f\"Test set: {input_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e402ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensors:\n",
      "Input: torch.Size([800, 4])\n",
      "Output: torch.Size([800, 1])\n",
      "Loss function: MSELoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Loss function: MSELoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# coverting to tensors\n",
    "\n",
    "input_train_tensor = torch.FloatTensor(input_train)\n",
    "input_test_tensor = torch.FloatTensor(input_test)\n",
    "output_train_tensor = torch.FloatTensor(output_train).unsqueeze(1)\n",
    "output_test_tensor = torch.FloatTensor(output_test).unsqueeze(1)\n",
    "\n",
    "print(f\"Training tensors:\")\n",
    "print(f\"Input: {input_train_tensor.shape}\")\n",
    "print(f\"Output: {output_train_tensor.shape}\")\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d522337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 1.0530\n",
      "Final loss: 1.0509\n",
      "Final loss: 1.0488\n",
      "Final loss: 1.0469\n",
      "Final loss: 1.0450\n",
      "Final loss: 1.0432\n",
      "Final loss: 1.0414\n",
      "Final loss: 1.0398\n",
      "Final loss: 1.0382\n",
      "Epoch [10/100], Loss: 1.0366\n",
      "Final loss: 1.0366\n",
      "Final loss: 1.0352\n",
      "Final loss: 1.0338\n",
      "Final loss: 1.0324\n",
      "Final loss: 1.0311\n",
      "Final loss: 1.0299\n",
      "Final loss: 1.0288\n",
      "Final loss: 1.0276\n",
      "Final loss: 1.0266\n",
      "Final loss: 1.0255\n",
      "Epoch [20/100], Loss: 1.0246\n",
      "Final loss: 1.0246\n",
      "Final loss: 1.0236\n",
      "Final loss: 1.0227\n",
      "Final loss: 1.0219\n",
      "Final loss: 1.0211\n",
      "Final loss: 1.0203\n",
      "Final loss: 1.0195\n",
      "Final loss: 1.0188\n",
      "Final loss: 1.0181\n",
      "Final loss: 1.0175\n",
      "Epoch [30/100], Loss: 1.0168\n",
      "Final loss: 1.0168\n",
      "Final loss: 1.0162\n",
      "Final loss: 1.0156\n",
      "Final loss: 1.0151\n",
      "Final loss: 1.0145\n",
      "Final loss: 1.0140\n",
      "Final loss: 1.0135\n",
      "Final loss: 1.0129\n",
      "Final loss: 1.0124\n",
      "Final loss: 1.0119\n",
      "Epoch [40/100], Loss: 1.0115\n",
      "Final loss: 1.0115\n",
      "Final loss: 1.0111\n",
      "Final loss: 1.0106\n",
      "Final loss: 1.0102\n",
      "Final loss: 1.0098\n",
      "Final loss: 1.0094\n",
      "Final loss: 1.0091\n",
      "Final loss: 1.0087\n",
      "Final loss: 1.0083\n",
      "Final loss: 1.0079\n",
      "Epoch [50/100], Loss: 1.0076\n",
      "Final loss: 1.0076\n",
      "Final loss: 1.0072\n",
      "Final loss: 1.0068\n",
      "Final loss: 1.0064\n",
      "Final loss: 1.0061\n",
      "Final loss: 1.0057\n",
      "Final loss: 1.0053\n",
      "Final loss: 1.0049\n",
      "Final loss: 1.0045\n",
      "Final loss: 1.0041\n",
      "Epoch [60/100], Loss: 1.0037\n",
      "Final loss: 1.0037\n",
      "Final loss: 1.0033\n",
      "Final loss: 1.0028\n",
      "Final loss: 1.0024\n",
      "Final loss: 1.0019\n",
      "Final loss: 1.0014\n",
      "Final loss: 1.0009\n",
      "Final loss: 1.0004\n",
      "Final loss: 0.9999\n",
      "Final loss: 0.9994\n",
      "Epoch [70/100], Loss: 0.9988\n",
      "Final loss: 0.9988\n",
      "Final loss: 0.9982\n",
      "Final loss: 0.9976\n",
      "Final loss: 0.9969\n",
      "Final loss: 0.9963\n",
      "Final loss: 0.9956\n",
      "Final loss: 0.9948\n",
      "Final loss: 0.9940\n",
      "Final loss: 0.9932\n",
      "Final loss: 0.9924\n",
      "Epoch [80/100], Loss: 0.9915\n",
      "Final loss: 0.9915\n",
      "Final loss: 0.9905\n",
      "Final loss: 0.9895\n",
      "Final loss: 0.9884\n",
      "Final loss: 0.9873\n",
      "Final loss: 0.9862\n",
      "Final loss: 0.9849\n",
      "Final loss: 0.9836\n",
      "Final loss: 0.9822\n",
      "Final loss: 0.9807\n",
      "Epoch [90/100], Loss: 0.9792\n",
      "Final loss: 0.9792\n",
      "Final loss: 0.9776\n",
      "Final loss: 0.9758\n",
      "Final loss: 0.9740\n",
      "Final loss: 0.9720\n",
      "Final loss: 0.9699\n",
      "Final loss: 0.9677\n",
      "Final loss: 0.9654\n",
      "Final loss: 0.9628\n",
      "Final loss: 0.9601\n",
      "Epoch [100/100], Loss: 0.9572\n",
      "Final loss: 0.9572\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predictions = model(input_train_tensor)\n",
    "    \n",
    "    loss = criterion(predictions, output_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    if ((epoch + 1) % 10) == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{no_of_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f\"Final loss: {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee64eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9112\n",
      "\n",
      "Test Metrics:\n",
      "Mean Squared Error (MSE): 0.9112\n",
      "Mean Absolute Error (MAE): 0.7431\n",
      "Root Mean Squared Error (RMSE): 0.9546\n",
      "\n",
      "Sample Predictions vs Actual:\n",
      "Sample 1: Predicted=0.036, Actual=-0.561\n",
      "Sample 2: Predicted=0.009, Actual=0.119\n",
      "Sample 3: Predicted=-0.001, Actual=-1.444\n",
      "Sample 4: Predicted=0.032, Actual=-0.180\n",
      "Sample 5: Predicted=0.029, Actual=-0.431\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(input_test_tensor)\n",
    "    test_loss = criterion(test_predictions, output_test_tensor)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "test_predictions_numpy = test_predictions.numpy().flatten()\n",
    "output_test_numpy = output_test_tensor.numpy().flatten()\n",
    "\n",
    "mse = np.mean((test_predictions_numpy - output_test_numpy) ** 2)\n",
    "mae = np.mean(np.abs(test_predictions_numpy - output_test_numpy))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nSample Predictions vs Actual:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}: Predicted={test_predictions_numpy[i]:.3f}, Actual={output_test_numpy[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c2f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualDF = pd.read_excel(\"Copy of Folds5x2_pp.xlsx\")\n",
    "actualDF_clean = actualDF.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2c2202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Data Shape: (9568, 5)\n",
      "Actual Data Columns: ['AT', 'V', 'AP', 'RH', 'PE']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Actual Data Shape: {actualDF_clean.shape}\")\n",
    "print(f\"Actual Data Columns: {actualDF_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1037dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_column = actualDF_clean.columns[-1]\n",
    "input_columns = [col for col in actualDF_clean.columns if col != output_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "496d8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (9568, 4), Output shape: (9568,)\n",
      "\n",
      "First 5 rows of real data:\n",
      "      AT      V       AP     RH      PE\n",
      "0  14.96  41.76  1024.07  73.17  463.26\n",
      "1  25.18  62.96  1020.04  59.08  444.37\n",
      "2   5.11  39.40  1012.16  92.14  488.56\n",
      "3  20.86  57.32  1010.24  76.64  446.48\n",
      "4  10.82  37.50  1009.23  96.62  473.90\n"
     ]
    }
   ],
   "source": [
    "input_data = actualDF_clean[input_columns].values\n",
    "output_data = actualDF_clean[output_column].values\n",
    "\n",
    "print(f\"Input shape: {input_data.shape}, Output shape: {output_data.shape}\")\n",
    "print(f\"\\nFirst 5 rows of real data:\")\n",
    "print(actualDF_clean[input_columns + [output_column]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81d1f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "AT: 1.81 to 37.11\n",
      "V: 25.36 to 81.56\n",
      "AP: 992.89 to 1033.30\n",
      "RH: 25.56 to 100.16\n",
      "PE: 420.26 to 495.76\n",
      "\n",
      "Normalized data:\n",
      "AT: -2.39 to 2.34\n",
      "V: -2.28 to 2.14\n",
      "AP: -3.43 to 3.37\n",
      "RH: -3.27 to 1.84\n",
      "PE: -2.00 to 2.43\n",
      "\n",
      "normalized input shape: (9568, 4), normalized output shape: (9568,)\n"
     ]
    }
   ],
   "source": [
    "scalar_input = StandardScaler().fit_transform(input_data)\n",
    "scalar_output = StandardScaler().fit_transform(output_data.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Original data:\")\n",
    "for i, col in enumerate(input_columns):\n",
    "    print(f\"{col}: {input_data[:, i].min():.2f} to {input_data[:, i].max():.2f}\")\n",
    "print(f\"{output_column}: {output_data.min():.2f} to {output_data.max():.2f}\")\n",
    "\n",
    "print(f\"\\nNormalized data:\")\n",
    "for i, col in enumerate(input_columns):\n",
    "    print(f\"{col}: {scalar_input[:, i].min():.2f} to {scalar_input[:, i].max():.2f}\")\n",
    "print(f\"{output_column}: {scalar_output.min():.2f} to {scalar_output.max():.2f}\")\n",
    "\n",
    "print(f\"\\nnormalized input shape: {scalar_input.shape}, normalized output shape: {scalar_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21409d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_real, input_test_real, output_train_real, output_test_real = train_test_split(\n",
    "    scalar_input, scalar_output, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "input_train_tensor_real = torch.FloatTensor(input_train_real)\n",
    "input_test_tensor_real = torch.FloatTensor(input_test_real)\n",
    "output_train_tensor_real = torch.FloatTensor(output_train_real).unsqueeze(1)\n",
    "output_test_tensor_real = torch.FloatTensor(output_test_real).unsqueeze(1)\n",
    "\n",
    "real_model = Autoencoder(input_size=4, output_size=1)\n",
    "criterion_real = nn.MSELoss()\n",
    "optimizer_real = optim.Adam(real_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447be1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/500], Loss: 0.9934\n",
      "Epoch [100/500], Loss: 0.7977\n",
      "Epoch [150/500], Loss: 0.1669\n",
      "Epoch [200/500], Loss: 0.0984\n",
      "Epoch [250/500], Loss: 0.0737\n",
      "Epoch [300/500], Loss: 0.0641\n",
      "Epoch [350/500], Loss: 0.0615\n",
      "Epoch [400/500], Loss: 0.0606\n",
      "Epoch [450/500], Loss: 0.0601\n",
      "Epoch [500/500], Loss: 0.0598\n",
      "\n",
      "Training completed!\n",
      "Final training loss: 0.0598\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "no_of_epochs_real = 500\n",
    "train_losses_real = []\n",
    "\n",
    "for epoch in range(no_of_epochs_real):\n",
    "    real_model.train()\n",
    "    optimizer_real.zero_grad()\n",
    "    \n",
    "    predictions_real = real_model(input_train_tensor_real)\n",
    "    \n",
    "    loss_real = criterion_real(predictions_real, output_train_tensor_real)\n",
    "    \n",
    "    loss_real.backward()\n",
    "    optimizer_real.step()\n",
    "    \n",
    "    train_losses_real.append(loss_real.item())\n",
    "    \n",
    "    if ((epoch + 1) % 50) == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{no_of_epochs_real}], Loss: {loss_real.item():.4f}')\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Final training loss: {train_losses_real[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bf425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss on Real Data: 0.0584\n",
      "\n",
      "Test Metrics on Real Data:\n",
      "Mean Squared Error (MSE): 0.0584\n",
      "Mean Absolute Error (MAE): 0.1881\n",
      "Root Mean Squared Error (RMSE): 0.2417\n",
      "\n",
      "Sample Predictions vs Actual on Real Data:\n",
      "Sample 1: Predicted=0.049, Actual=0.053\n",
      "Sample 2: Predicted=-0.982, Actual=-1.058\n",
      "Sample 3: Predicted=-1.157, Actual=-0.802\n",
      "Sample 4: Predicted=-0.980, Actual=-1.170\n",
      "Sample 5: Predicted=1.465, Actual=1.623\n",
      "Sample 6: Predicted=-0.925, Actual=-1.072\n",
      "Sample 7: Predicted=-0.305, Actual=-0.110\n",
      "Sample 8: Predicted=-1.162, Actual=-1.122\n",
      "Sample 9: Predicted=-1.228, Actual=-1.256\n",
      "Sample 10: Predicted=1.077, Actual=0.709\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "real_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions_real = real_model(input_test_tensor_real)\n",
    "    test_loss_real = criterion_real(test_predictions_real, output_test_tensor_real)\n",
    "\n",
    "print(f\"Test Loss on Real Data: {test_loss_real.item():.4f}\")\n",
    "\n",
    "test_predictions_real_numpy = test_predictions_real.numpy().flatten()\n",
    "output_test_real_numpy = output_test_tensor_real.numpy().flatten()\n",
    "\n",
    "mse_real = np.mean((test_predictions_real_numpy - output_test_real_numpy) ** 2)\n",
    "mae_real = np.mean(np.abs(test_predictions_real_numpy - output_test_real_numpy))\n",
    "rmse_real = np.sqrt(mse_real)\n",
    "\n",
    "print(f\"\\nTest Metrics on Real Data:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_real:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_real:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_real:.4f}\")\n",
    "\n",
    "print(f\"\\nSample Predictions vs Actual on Real Data:\")\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i+1}: Predicted={test_predictions_real_numpy[i]:.3f}, Actual={output_test_real_numpy[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
